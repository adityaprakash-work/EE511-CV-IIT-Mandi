{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DEPENDENCIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(Xtr, Ytr), (Xte, Yte) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = Xtr.reshape(-1, 784)\n",
    "Xte = Xte.reshape(-1, 784)\n",
    "Ytr = np.eye(10)[Ytr]\n",
    "Yte = np.eye(10)[Yte]\n",
    "\n",
    "# Normalize\n",
    "Xtr = Xtr / 255\n",
    "Xte = Xte / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, accu=False, title=\"Training vs Validation Loss\"):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    sns.lineplot(\n",
    "        x=range(1, len(history[\"loss\"]) + 1),\n",
    "        y=history[\"loss\"],\n",
    "        label=\"Training Loss\",\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        x=range(1, len(history[\"val_loss\"]) + 1),\n",
    "        y=history[\"val_loss\"],\n",
    "        label=\"Validation Loss\",\n",
    "    )\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    if accu and \"accuracy\" in history and \"val_accuracy\" in history:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.set_style(\"darkgrid\")\n",
    "        sns.lineplot(\n",
    "            x=range(1, len(history[\"accuracy\"]) + 1),\n",
    "            y=history[\"accuracy\"],\n",
    "            label=\"Training Accuracy\",\n",
    "        )\n",
    "        sns.lineplot(\n",
    "            x=range(1, len(history[\"val_accuracy\"]) + 1),\n",
    "            y=history[\"val_accuracy\"],\n",
    "            label=\"Validation Accuracy\",\n",
    "        )\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_images(\n",
    "    original_images, reconstructed_images, title=\"Original vs Reconstructed Images\"\n",
    "):\n",
    "    fig, axes = plt.subplots(2, 10, figsize=(16, 4))\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    for i in range(10):\n",
    "        axes[0, i].imshow(original_images[i].reshape(28, 28), cmap=\"gray\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "        axes[1, i].imshow(reconstructed_images[i].reshape(28, 28), cmap=\"gray\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Neural Network (scratch)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNet:\n",
    "    def __init__(self, inp_units, hid_units, out_units):\n",
    "        self.inp_units = inp_units\n",
    "        self.hid_units = hid_units\n",
    "        self.out_units = out_units\n",
    "\n",
    "        # Parameters\n",
    "        self.W1 = np.random.randn(self.inp_units, self.hid_units)\n",
    "        self.b1 = np.random.randn(self.hid_units)\n",
    "        self.W2 = np.random.randn(self.hid_units, self.out_units)\n",
    "        self.b2 = np.random.randn(self.out_units)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        # Clip x values to prevent overflow\n",
    "        x = np.clip(x, -500, 500)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def _sigmoid_prime(self, x):\n",
    "        return self._sigmoid(x) * (1 - self._sigmoid(x))\n",
    "\n",
    "    def _mse(self, y, y_hat):\n",
    "        return np.square(y - y_hat).mean()\n",
    "\n",
    "    def _mse_prime(self, y, y_hat):\n",
    "        return 2 * (y_hat - y) / y.size\n",
    "\n",
    "    def _accuracy(self, y, y_hat, threshold=0.5):\n",
    "        return np.sum(y == (y_hat > threshold)) / y.size\n",
    "\n",
    "    def _forward_h(self, x):\n",
    "        return self._sigmoid(np.dot(x, self.W1) + self.b1)\n",
    "\n",
    "    def _forward_o(self, x):\n",
    "        return self._sigmoid(np.dot(x, self.W2) + self.b2)\n",
    "\n",
    "    def _forward(self, x):\n",
    "        return self._forward_o(self._forward_h(x))\n",
    "\n",
    "    def _backward_o(self, x, y, y_hat):\n",
    "        dL_dz = self._mse_prime(y, y_hat) * self._sigmoid_prime(y_hat)\n",
    "        dL_dW = np.dot(self._forward_h(x).T, dL_dz)\n",
    "        dL_db = np.sum(dL_dz, axis=0)\n",
    "        return dL_dW, dL_db, dL_dz\n",
    "\n",
    "    def _backward_h(self, x, dL_dz):\n",
    "        dL_dW = np.dot(\n",
    "            x.T, np.dot(dL_dz, self.W2.T) * self._sigmoid_prime(self._forward_h(x))\n",
    "        )\n",
    "        dL_db = np.sum(\n",
    "            np.dot(dL_dz, self.W2.T) * self._sigmoid_prime(self._forward_h(x)),\n",
    "            axis=0,\n",
    "        )\n",
    "        return dL_dW, dL_db\n",
    "\n",
    "    def _backward(self, x, y, y_hat, learning_rate):\n",
    "        dL_dW2, dL_db2, dL_dz2 = self._backward_o(x, y, y_hat)\n",
    "        dL_dW1, dL_db1 = self._backward_h(x, dL_dz2)\n",
    "        self.W1 -= learning_rate * dL_dW1 \n",
    "        self.b1 -= learning_rate * dL_db1 \n",
    "        self.W2 -= learning_rate * dL_dW2 \n",
    "        self.b2 -= learning_rate * dL_db2 \n",
    "\n",
    "    def train(self, x, y, x_val, y_val, batch_size=16, epochs=10, learning_rate=1e-3):\n",
    "        history = {\n",
    "            \"loss\": [],\n",
    "            \"val_loss\": [],\n",
    "            \"accuracy\": [],\n",
    "            \"val_accuracy\": [],\n",
    "        }\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "            for i in tqdm(range(0, x.shape[0], batch_size)):\n",
    "                x_batch = x[i : i + batch_size]\n",
    "                y_batch = y[i : i + batch_size]\n",
    "                y_hat = self._forward(x_batch)\n",
    "                self._backward(x_batch, y_batch, y_hat, learning_rate)\n",
    "            y_hat = self._forward(x)\n",
    "            y_val_hat = self._forward(x_val)\n",
    "            history[\"loss\"].append(self._mse(y, y_hat))\n",
    "            history[\"val_loss\"].append(self._mse(y_val, y_val_hat))\n",
    "            history[\"accuracy\"].append(self._accuracy(y, y_hat))\n",
    "            history[\"val_accuracy\"].append(self._accuracy(y_val, y_val_hat))\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1089/3750 [00:02<00:06, 403.41it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\workspace-a\\EE511-CV-IIT-Mandi\\A3\\Q2\\code.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Training\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m FeedForwardNet(\u001b[39m784\u001b[39m, \u001b[39m128\u001b[39m, \u001b[39m10\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain(Xtr, Ytr, Xte, Yte, epochs\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Plotting\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plot_history(history, accu\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\workspace-a\\EE511-CV-IIT-Mandi\\A3\\Q2\\code.ipynb Cell 10\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     y_batch \u001b[39m=\u001b[39m y[i : i \u001b[39m+\u001b[39m batch_size]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     y_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(x_batch)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backward(x_batch, y_batch, y_hat, learning_rate)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m y_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m y_val_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(x_val)\n",
      "\u001b[1;32mc:\\workspace-a\\EE511-CV-IIT-Mandi\\A3\\Q2\\code.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_backward\u001b[39m(\u001b[39mself\u001b[39m, x, y, y_hat, learning_rate):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     dL_dW2, dL_db2, dL_dz2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backward_o(x, y, y_hat)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     dL_dW1, dL_db1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_h(x, dL_dz2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW1 \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m learning_rate \u001b[39m*\u001b[39m dL_dW1 \n",
      "\u001b[1;32mc:\\workspace-a\\EE511-CV-IIT-Mandi\\A3\\Q2\\code.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_backward_o\u001b[39m(\u001b[39mself\u001b[39m, x, y, y_hat):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     dL_dz \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mse_prime(y, y_hat) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sigmoid_prime(y_hat)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     dL_dW \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_h(x)\u001b[39m.\u001b[39mT, dL_dz)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     dL_db \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(dL_dz, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m dL_dW, dL_db, dL_dz\n",
      "\u001b[1;32mc:\\workspace-a\\EE511-CV-IIT-Mandi\\A3\\Q2\\code.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_h\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/workspace-a/EE511-CV-IIT-Mandi/A3/Q2/code.ipynb#X10sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sigmoid(np\u001b[39m.\u001b[39;49mdot(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW1) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb1)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model = FeedForwardNet(784, 128, 10)\n",
    "history = model.train(Xtr, Ytr, Xte, Yte, epochs=25)\n",
    "\n",
    "# Plotting\n",
    "plot_history(history, accu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Autoencoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),  \n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 28 * 28),  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model_ae = Autoencoder()\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model_ae.parameters(), lr=1e-3)\n",
    "epochs = 1\n",
    "batch_size = 16\n",
    "history = {\n",
    "    \"loss\": [],\n",
    "    \"val_loss\": [],\n",
    "}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    for i in tqdm(range(0, Xtr.shape[0], batch_size)):\n",
    "        x_batch = torch.from_numpy(Xtr[i : i + batch_size]).float()\n",
    "        y_batch = torch.from_numpy(Xtr[i : i + batch_size]).float()\n",
    "        x_enc = model_ae.encoder(x_batch)\n",
    "        x_rec = model_ae.decoder(x_enc)\n",
    "        loss_val = loss(x_rec, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "    x_enc = model_ae.encoder(torch.from_numpy(Xtr).float())\n",
    "    x_rec = model_ae.decoder(x_enc)\n",
    "    x_val_enc = model_ae.encoder(torch.from_numpy(Xte).float())\n",
    "    x_val_rec = model_ae.decoder(x_val_enc)\n",
    "    history[\"loss\"].append(loss(x_rec, torch.from_numpy(Xtr).float()).item())\n",
    "    history[\"val_loss\"].append(loss(x_val_rec, torch.from_numpy(Xte).float()).item())\n",
    "\n",
    "# Plotting\n",
    "plot_history(history)\n",
    "\n",
    "# Plotting\n",
    "x_enc = model_ae.encoder(torch.from_numpy(Xte).float()).detach().numpy()\n",
    "x_rec = model_ae.decoder(torch.from_numpy(x_enc).float()).detach().numpy()\n",
    "plot_images(Xte, x_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **MLP with Sigmoid, MSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLayerPerceptron3, self).__init__()\n",
    "        self.h = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.o = nn.Sequential(\n",
    "            nn.Linear(128, 10),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.h(x)\n",
    "        x = self.o(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model_3 = MultiLayerPerceptron3()\n",
    "model_3 = model_3.to(device)\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model_3.parameters(), lr=1e-3)\n",
    "epochs = 25\n",
    "batch_size = 16\n",
    "history = {\n",
    "    \"loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"val_accuracy\": [],\n",
    "}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    for i in tqdm(range(0, Xtr.size(0), batch_size)):\n",
    "        x_batch = Xtr[i : i + batch_size]\n",
    "        y_batch = Ytr[i : i + batch_size]\n",
    "        y_hat = model_3.h(x_batch)\n",
    "        y_hat = model_3.o(y_hat)\n",
    "        loss_val = loss(y_hat, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    y_hat = model_3.h(Xtr)\n",
    "    y_hat = model_3.o(y_hat)\n",
    "    y_hat_val = model_3.h(Xte)\n",
    "    y_hat_val = model_3.o(y_hat_val)\n",
    "    history[\"loss\"].append(loss(y_hat, Ytr).item())\n",
    "    history[\"val_loss\"].append(loss(y_hat_val, Yte).item())\n",
    "    history[\"accuracy\"].append(\n",
    "        torch.sum(Ytr == (y_hat > 0.5)).item() / Ytr.size(0)\n",
    "    )\n",
    "    history[\"val_accuracy\"].append(\n",
    "        torch.sum(Yte == (y_hat_val > 0.5)).item() / Yte.size(0)\n",
    "    )\n",
    "\n",
    "# Plotting\n",
    "plot_history(history, accu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLayerPerceptron4, self).__init__()\n",
    "        self.h = model_ae.encoder\n",
    "        self.h[0].weight.requires_grad = False\n",
    "        self.o = nn.Sequential(\n",
    "            nn.Linear(128, 10),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.h(x)\n",
    "        x = self.o(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model_4 = MultiLayerPerceptron4()\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model_4.parameters(), lr=1e-3, momentum=0.9)\n",
    "epochs = 25\n",
    "batch_size = 16\n",
    "history = {\n",
    "    \"loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"val_accuracy\": [],\n",
    "}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    for i in tqdm(range(0, Xtr.shape[0], batch_size)):\n",
    "        x_batch = torch.from_numpy(Xtr[i : i + batch_size]).float()\n",
    "        y_batch = torch.from_numpy(Xtr[i : i + batch_size]).float()\n",
    "        y_hat = model_4(x_batch)\n",
    "        loss_val = loss(y_hat, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "    y_hat = model_4(torch.from_numpy(Xtr).float())\n",
    "    y_val_hat = model_4(torch.from_numpy(Xte).float())\n",
    "    history[\"loss\"].append(loss(y_hat, torch.from_numpy(Xtr).float()).item())\n",
    "    history[\"val_loss\"].append(loss(y_val_hat, torch.from_numpy(Xte).float()).item())\n",
    "    history[\"accuracy\"].append(\n",
    "        np.sum(Ytr == (y_hat.detach().numpy() > 0.5)) / Ytr.size\n",
    "    )\n",
    "    history[\"val_accuracy\"].append(\n",
    "        np.sum(Yte == (y_val_hat.detach().numpy() > 0.5)) / Yte.size\n",
    "    )\n",
    "\n",
    "# Plotting\n",
    "plot_history(history, accu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **LeNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model = LeNet5()\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "epochs = 25\n",
    "batch_size = 16\n",
    "history = {\n",
    "    \"loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"val_accuracy\": [],\n",
    "}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    for i in tqdm(range(0, Xtr.shape[0], batch_size)):\n",
    "        x_batch = torch.from_numpy(Xtr[i : i + batch_size]).float().reshape(-1, 1, 28, 28)\n",
    "        y_batch = torch.from_numpy(Ytr[i : i + batch_size]).float()\n",
    "        y_hat = model(x_batch)\n",
    "        loss_val = loss(y_hat, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "    y_hat = model(torch.from_numpy(Xtr).float().reshape(-1, 1, 28, 28))\n",
    "    y_val_hat = model(torch.from_numpy(Xte).float().reshape(-1, 1, 28, 28))\n",
    "    history[\"loss\"].append(loss(y_hat, torch.from_numpy(Ytr).float()).item())\n",
    "    history[\"val_loss\"].append(loss(y_val_hat, torch.from_numpy(Yte).float()).item())\n",
    "    history[\"accuracy\"].append(\n",
    "        np.sum(Ytr == (y_hat.detach().numpy() > 0.5)) / Ytr.size\n",
    "    )\n",
    "    history[\"val_accuracy\"].append(\n",
    "        np.sum(Yte == (y_val_hat.detach().numpy() > 0.5)) / Yte.size\n",
    "    )\n",
    "\n",
    "# Plotting\n",
    "plot_history(history, accu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Implement a 3 layer MLP using PyTorch use sigmoid func;on as \n",
    "ac;va;on in all layers and ini;alize the first 2-layers with pretrained \n",
    "weights as per the deep belief network using autoencoders then fine \n",
    "tune it using MSE and SGD with autograd. Use appropriate learning \n",
    "rate or a momentum on weights. Compare the results of the III and IV \n",
    "for training vs valida;on losses and accuracies. Plot the train and \n",
    "valida;on curves in a single figure. -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
